{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. Environment Setup\n",
    "# Note: Ensure 'GROQ_API_KEY' is set in your environment variables\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "# 2. LLM Initialization (Using Groq-supported models)\n",
    "# Llama 3.3 70B is excellent for reasoning and humor\n",
    "generator_llm = ChatGroq(model='llama-3.3-70b-versatile', temperature=0.7)\n",
    "evaluator_llm = ChatGroq(model='llama-3.3-70b-versatile', temperature=0.1)\n",
    "optimizer_llm = ChatGroq(model='llama-3.3-70b-versatile', temperature=0.6)\n",
    "\n",
    "# 3. Structured Output Definition\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"Feedback for the tweet.\")\n",
    "\n",
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)\n",
    "\n",
    "# 4. State Definition\n",
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int\n",
    "    # Annotated with operator.add will append new items to the list automatically\n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]\n",
    "\n",
    "# 5. Node Functions\n",
    "def generate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a funny and clever Twitter/X influencer.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Write a short, original, and hilarious tweet on the topic: \"{state['topic']}\".\n",
    "Rules:\n",
    "- Do NOT use question-answer format.\n",
    "- Max 280 characters.\n",
    "- Use observational humor, irony, sarcasm, or cultural references.\n",
    "- Use simple, day to day english.\n",
    "\"\"\")\n",
    "    ]\n",
    "    response = generator_llm.invoke(messages).content\n",
    "    return {'tweet': response, 'tweet_history': [response]}\n",
    "\n",
    "def evaluate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a ruthless Twitter critic. You evaluate based on humor, originality, and virality.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Evaluate this tweet: \"{state['tweet']}\"\n",
    "\n",
    "Auto-reject if:\n",
    "- It's Q&A format.\n",
    "- It exceeds 280 characters.\n",
    "- It ends with a generic/weak summary line.\n",
    "\n",
    "Respond ONLY in structured format.\n",
    "\"\"\")\n",
    "    ]\n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "    return {\n",
    "        'evaluation': response.evaluation, \n",
    "        'feedback': response.feedback, \n",
    "        'feedback_history': [response.feedback]\n",
    "    }\n",
    "\n",
    "def optimize_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You punch up tweets for virality based on feedback.\"),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "Improve this tweet based on the feedback: \"{state['feedback']}\"\n",
    "Topic: \"{state['topic']}\"\n",
    "Current Tweet: {state['tweet']}\n",
    "\"\"\")\n",
    "    ]\n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    # Increment iteration count\n",
    "    return {'tweet': response, 'iteration': state['iteration'] + 1, 'tweet_history': [response]}\n",
    "\n",
    "# 6. Routing Logic\n",
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else:\n",
    "        return 'needs_improvement'\n",
    "\n",
    "# 7. Graph Construction\n",
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    'evaluate', \n",
    "    route_evaluation, \n",
    "    {'approved': END, 'needs_improvement': 'optimize'}\n",
    ")\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "# 8. Execution\n",
    "if __name__ == \"__main__\":\n",
    "    initial_input = {\n",
    "        \"topic\": \"Why people still use 'Reply All' on corporate emails\",\n",
    "        \"iteration\": 1,\n",
    "        \"max_iteration\": 3,\n",
    "        \"tweet_history\": [],     # Initialize lists for operator.add\n",
    "        \"feedback_history\": []\n",
    "    }\n",
    "\n",
    "    print(\"--- Starting Agentic Workflow ---\\n\")\n",
    "    result = workflow.invoke(initial_input)\n",
    "\n",
    "    print(\"\\n--- TWEET HISTORY ---\")\n",
    "    for i, t in enumerate(result['tweet_history'], 1):\n",
    "        print(f\"Version {i}: {t}\\n\")\n",
    "\n",
    "    print(f\"FINAL STATUS: {result['evaluation']}\")\n",
    "    print(f\"CRITIC FEEDBACK: {result['feedback']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
